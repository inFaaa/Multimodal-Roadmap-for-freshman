# Multimodal-Roadmap-for-freshman
 本项目用于Multimodal领域新手的学习路线，包括该领域的经典论文，项目及课程。旨在希望学习者在一定的时间内达到对这个领域有较为深刻的认知，能够自己进行的独立研究。

 前2个月精读经典+实现，然后把深度学习基础过一遍，接下来2个月把领域新的东西泛读+精读过一遍然后做一些别人的idea（帮忙跑实验，如果能在企业研究岗最好），最后两个月开始想一些独立的idea去面向会议进行投稿研究，到投出第一篇为止就算度过freshman阶段。

#### 常用网站&必读资料

- [multimodal论文](https://github.com/pliang279/awesome-multimodal-ml)
- [image captioning论文](https://github.com/zhjohnchan/awesome-image-captioning#2019)
- [visual grounding论文](https://github.com/qy-feng/awesome-visual-grounding)
- [一文纵览 Vision-and-Language 领域最新研究与进展](https://www.leiphone.com/news/201905/nJPT0qyibjtM09wE.html)
- [从 Vision 到 Language 再到 Action，万字漫谈三年跨域信息融合研究](https://mp.weixin.qq.com/s?__biz=MzA5ODEzMjIyMA==&mid=2247496394&idx=1&sn=22197341f2a5104b70ec9a6acee3d360&source=41#wechat_redirect)
- [Arxiv](http://www.arxiv-sanity.com/top)
- [Paper with code](https://paperswithcode.com/)
- [AIdeadline][https://aideadlin.es/?sub=]
- [Overleaf](https://www.overleaf.com/project)
- Latex
- [张士峰学长分享](https://www.shenlanxueyuan.com/open/course/59)
- Rebuttal



## About 2 months（单步调试+精读）

5-20篇论文代表基本理解了相关主题，或许对于进一步理解技术实现足够了。

50-100篇论文，你将会对这一领域有一个非常好的的理解。

#### Week 1

​	《Attention is all you need》

​	《Show and Tell: A Neural Image Caption Generator》

#### Week 2

​	《Self-critical Sequence Training for Image Captioning》

​	《Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering》

#### Week 3

​	《SCA-CNN-Spatial and Channel-wise Attention in Convolutional Networks》

​	《Show, Attend and Tell--Neural Image CaptionGeneration with Visual Attention》

​	[BLEU、Meteor、ROUGE、CIDEr 和 SPICE](https://www.jianshu.com/p/60deff0f64e1)

#### Week 4

​	《Show, Control and Tell--A Framework for Generating Controllable and Grounded Captions》

​	《[Spice: Semantic propositional image caption evaluation](https://link.springer.com/chapter/10.1007/978-3-319-46454-1_24)》

#### Week 5

​	《[Unsupervised Image Captioning](https://arxiv.org/abs/1811.10787)》

​	《[Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning](http://www.aclweb.org/anthology/P18-1238)》

#### Week 6

​	《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》